
---
title: "Power"
output: html_document
---
<a href="http://rinterested.github.io/statistics/index.html">
<img HEIGHT="50" WIDTH="50" src="https://cloud.githubusercontent.com/assets/9312897/10454865/aa4dc136-7185-11e5-8dd3-89d352ff577f.png"></a>


<br><br>


*Motivating scenario: Meta-alpha protein (MAP) levels of 25 mg/mL are considered top normal in the population at large ($\mu_o$). However, we are studying a group of 20 ($n=20$) subjects with a severe deficit in glycophospholids (GLy) with MAP concentrations of 28 mg/mL with a standard deviation of 5 mg/mL. The question is what is the power of a $t$ test to reject the $H_o$ hypothesis that the people with deficit in GLy have higher levels of MAP?*

These plots show the dependence of power on the true mean of the alternative hypothesis: the closer it is to the mean of $H_o$ the less power to reject $H_o$ when it is false. At its limit, when both means coincide, the power becomes identical to the $\alpha$ risk.


<img height="600" width="500" src="https://cloud.githubusercontent.com/assets/9312897/10419988/5ef2c0be-7055-11e5-9c7d-5d562ff48d7e.png">



---

These plots show the dependence of power on the true mean of the alternative hypothesis: the closer it is to the mean of $H_o$ the less power to reject $H_o$ when it is false. At its limit, when both means coincide, the power becomes identical to the $alpha$ risk.

---

The probability of a type II error is $\beta$. In other words, it is the probability of *not* rejecting $H_o$ when it is false.

Therefore, probability of rejecting $H_o$ when it is false will be $1 - \beta$. And this is exactly the definition of *POWER*:

<br>

$POWER \, = \, 1\,-\,\beta$

<br>

Power is exactly the probability that the test statistic lies in the rejection region *under* the premise that $H_a$ is correct.

For a single-group mean test we are comparing a normalized mean to a $t$ quantile to test if the group mean belongs to a different population, i.e. $H_a: \mu_a>\mu_o$.

<br>

$p\,\Big(\Large\frac{\bar X - \mu_o}{s/\sqrt{n}}\,> t_{1-\alpha,\,n-1}|\mu=\mu_a\Big)$

<br>

However, if $n$ is large we can do instead normal calculations:

<br>

$p\,\Big(\Large\frac{\bar X - \mu_o}{s/\sqrt{n}}\,> z_{1-\alpha}|\mu=\mu_a\Big)$

<br>

$\Large=\,p\Big(\Large\frac{\bar X - \mu_a \, + \mu_a -\mu_o}{s/\sqrt{n}}\,> z_{1-\alpha}|\mu=\mu_a\Big)$

<br>

$\Large=\,p\Big(\Large\frac{\bar X - \mu_a}{\sigma/\sqrt{n}} > \,z_{1-\alpha}\, -\frac{\mu_a -\mu_o}{s/\sqrt{n}}|\mu=\mu_a\Big)$

<br>

$\Large=\,p\Big(Z> \, z_{1-\alpha} -\frac{\mu_a -\mu_o}{s/\sqrt{n}}|\mu=\mu_a\Big)$


But we started off saying that we were comparing to a $t$ quantile, so how do we calculate power for a $t$ test:

$p\,\Big(\frac{\bar X - \mu_o}{s/\sqrt{n}}\,> t_{(1-\alpha, n-1)}\,|\mu=\mu_a\Big)$
<br>

$p\,\Big(\sqrt{n} (\bar X - \mu_o)\,> t_{(1-\alpha, n-1)}\, s\,|\mu=\mu_a\Big)$
<br>

$p\,\Big(\frac{\sqrt{n}\,(\bar X - \mu_o)}{\sigma}\,> t_{(1-\alpha, n-1)}\,\frac{s}{\sigma}\,|\mu=\mu_a\Big)$
<br>

$p\,\Big(\Large \frac{\sqrt{n}\,(\bar X - \mu_a)}{\sigma} + \frac{\sqrt{n}\,(\mu_a - \mu_o)}{\sigma}\,> \frac{t_{(1-\alpha, n-1)}}{\sqrt{n-1}}\,\sqrt{\frac{(n-1)\,s^2}{\sigma^2}}\,\,|\mu=\mu_a\Big)$
<br>


$p\,\Big(\Large \frac{\sqrt{n}\,(\bar X - \mu_a)}{\sigma} + \frac{\sqrt{n}\,(\mu_a - \mu_o)}{\sigma}\,> \frac{t_{(1-\alpha, n-1)}}{\sqrt{n-1}}\,\sqrt{\chi^2_{n-1}}\,\,|\mu=\mu_a\Big)$


For this last step refer to:



<a href="https://math.stackexchange.com/questions/1386238/proof-that-frac-displaystyle-sum-x-1n-x-barx2-sigma2-sim">Proof of Chi Square distribution of ratio of $\sim s^2/\sigma^2$</a>. And remember:

$s^2=\frac{\sum(X-\bar{X})^2}{n-1}$.


<br>

Since the last equations involve more complex (bivariate) calculations, the power calculation can be achieved via Monte Carlo simulation:

```{r}
simuls <- 1e5         # Number of simulations
n <- 20               # Sample size 
sigma <- 5            # Standard deviation
mu_0 <- 25            # The mean we assume under Ho
mu_a <- 28            # The mean under Ha
Z  <- rnorm(simuls)   # Part of the inequality above
chisqr <- rchisq(simuls, df = n - 1)
t <- qt(.95, n - 1)
# The power is:
mean(Z + sqrt(n) * (mu_a - mu_0) / sigma > t / sqrt(n - 1) * sqrt(chisqr))
```

RELATIONSHIPS:

1. Power goes up as $\alpha$ is larger.

2. Power of a one-sided test is greater than the power of the associated two-sided test - just think of it in terms of smaller $\alpha$ cuts ($\alpha/2$) 

3. Power goes up the further $\mu_a$ gets away from $\mu_o$.

4. Power goes up as $n$ goes up.

---

<a href="http://rinterested.github.io/statistics/index.html">Home Page</a>
