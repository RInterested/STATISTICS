<br>
<a href="http://rinterested.github.io/statistics/index.html">
<img HEIGHT="20" WIDTH="80" src="https://cloud.githubusercontent.com/assets/9312897/10556783/a27a26fa-745c-11e5-9b1a-2d5bd737387a.PNG"></a>

###POWER CALCULATIONS:

*Motivating scenario: Meta-alpha protein (MAP) levels of 25 mg/mL are considered top normal in the population at large ($\mu_o$). However, we are studying a group of 20 ($n=20$) subjects with a severe deficit in glycophospholids (GLy) with MAP concentrations of 28 mg/mL with a standard deviation of 5 mg/mL. The question is what is the power of a $t$ test to reject the $H_o$ hypothesis when it is false, and conclude that people with deficit in GLy have higher levels of MAP?*

These plots show the dependence of power on the true mean of the alternative hypothesis: the closer it is to the mean of $H_o$ the less power to reject $H_o$ when it is false. At its limit, when both means coincide, the power becomes identical to the $\alpha$ risk.


<img height="600" width="500" src="https://cloud.githubusercontent.com/assets/9312897/10419988/5ef2c0be-7055-11e5-9c7d-5d562ff48d7e.png">



---

These plots show the dependence of power on the true mean of the alternative hypothesis: the closer it is to the mean of $H_o$ the less power to reject $H_o$ when it is false. At its limit, when both means coincide, the power becomes identical to the $alpha$ risk.

---

The probability of a type II error is $\beta$. In other words, it is the probability of *not* rejecting $H_o$ when it is false.

Therefore, probability of rejecting $H_o$ when it is false will be $1 - \beta$. And this is exactly the definition of *POWER*:

<br>

$POWER \, = \, 1\,-\,\beta$

<br>

Power is exactly the probability that the test statistic lies in the rejection region *under* the premise that $H_a$ is correct.

For a single-group mean test we are comparing a normalized mean to a $t$ quantile to test if the group mean belongs to a different population, i.e. $H_a: \mu_a>\mu_o$.

<br>

$p\,\Big(\Large\frac{\bar X - \mu_o}{s/\sqrt{n}}\,> t_{1-\alpha,\,n-1}|\mu=\mu_a\Big)$

<br>

However, if $n$ is large we can do instead normal calculations:

<br>

$p\,\Big(\Large\frac{\bar X - \mu_o}{s/\sqrt{n}}\,> z_{1-\alpha}|\mu=\mu_a\Big)$

<br>

$\Large=\,p\Big(\Large\frac{\bar X - \mu_a \, + \mu_a -\mu_o}{s/\sqrt{n}}\,> z_{1-\alpha}|\mu=\mu_a\Big)$

<br>

$\Large=\,p\Big(\Large\frac{\bar X - \mu_a}{\sigma/\sqrt{n}} > \,z_{1-\alpha}\, -\frac{\mu_a -\mu_o}{s/\sqrt{n}}|\mu=\mu_a\Big)$

<br>

$\Large=\,p\Big(Z> \, z_{1-\alpha} -\frac{\mu_a -\mu_o}{s/\sqrt{n}}|\mu=\mu_a\Big)$

---

Here're two examples from a Coursera course:

1. Researchers would like to conduct a study of $100$ healthy adults to detect a four year mean brain volume loss of $0.01 mm^3$. Assume that the standard deviation of four year volume loss in this population is $0.004 mm^3$. What would be the power of the study for a 5% one sided test versus a null hypothesis of
no volume loss?

The hypothesis is $H_o: \mu_{\Delta}=0$ v. $H_a: \mu_{\Delta}>0$ where $\mu_{\Delta}$ is the volume loss. The test statistics is $10\frac{\bar X_{\Delta}}{0.04}$ which is rejected if it is larger than $Z_{0.95}=1.645$.
We want to calculate:

$P\left(\frac{\bar X_\Delta}{\sigma_\Delta / 10} > 1.645 ~|~ \mu_\Delta = .01\right)
= P\left( \frac{\bar X_\Delta - .01}{.004} > 1. 645 - \frac{.01}{.004} ~|~ \mu_\Delta = .01\right)
= P(Z > âˆ’.855) = .80$

Or note that $\bar X_{\Delta}$ is $N(0.01,0.004)$ under the alternative and we want the $P(\bar X_{\Delta} > 1.645*0.004$ under $H_a$.

```{}
pnorm(1.645 * 0.004, mean = 0.01, sd = 0.004, lower.tail = FALSE)
```

2. Researchers would like to conduct a study of $n$ healthy adults to detect a four year mean brain volume loss of $0.01 mm^3$. Assume that the standard deviation of four year volume loss in this population is $0.004 mm^3$.

What would be the value of $n$ needded for $90\%$ power of type one error rate of $5\%$ one sided test versus a null hypothesis of no volume loss?

The hypothesis is $H_o: \mu_{\Delta}=0$ v. $H_a: \mu_{\Delta}>0$ where $\mu_{\Delta}$ is the volume loss. The test statistics is $\frac{\bar X_{\Delta}}{0.04/\sqrt{n}}$ which is rejected if it is larger than $Z_{0.95}=1.645$.
We want to calculate:

$P\left(\frac{\bar X_\Delta}{\sigma_\Delta / \sqrt{n}} > 1.645 ~|~ \mu_\Delta = .01\right)
= P\left( \frac{\bar X_\Delta - .01}{.04 / \sqrt{n}} > 1. 645 - \frac{.01}{.04 / \sqrt{n}} ~|~ \mu_\Delta = .01\right)
= P(Z > 1.645 - \sqrt{n} / 4) = .90$

So we need $1.645 - \sqrt{n} / 4 = Z_{.10} = -1.282$ and thus $n = ( 4 * (1.645 + 1.282)  )^ 2$

```{r}
ceiling((4 * (qnorm(0.95) - qnorm(0.1)))^2)
```

---

But we started off saying that we were comparing to a $t$ quantile, so how do we calculate power for a $t$ test:

$p\,\Big(\frac{\bar X - \mu_o}{s/\sqrt{n}}\,> t_{(1-\alpha, n-1)}\,|\mu=\mu_a\Big)$
<br><br>

$p\,\Big(\sqrt{n} (\bar X - \mu_o)\,> t_{(1-\alpha, n-1)}\, s\,|\mu=\mu_a\Big)$
<br><br>

$p\,\Big(\frac{\sqrt{n}\,(\bar X - \mu_o)}{\sigma}\,> t_{(1-\alpha, n-1)}\,\frac{s}{\sigma}\,|\mu=\mu_a\Big)$
<br><br>

$p\,\Big(\Large \frac{\sqrt{n}\,(\bar X - \mu_a)}{\sigma} + \frac{\sqrt{n}\,(\mu_a - \mu_o)}{\sigma}\,> \frac{t_{(1-\alpha, n-1)}}{\sqrt{n-1}}\,\sqrt{\frac{(n-1)\,s^2}{\sigma^2}}\,\,|\mu=\mu_a\Big)$
<br><br>


$p\,\Big(\Large \frac{\sqrt{n}\,(\bar X - \mu_a)}{\sigma} + \frac{\sqrt{n}\,(\mu_a - \mu_o)}{\sigma}\,> \frac{t_{(1-\alpha, n-1)}}{\sqrt{n-1}}\,\sqrt{\chi^2_{n-1}}\,\,|\mu=\mu_a\Big)$
<br><br>


$p\,\Big(\Large Z + \frac{\sqrt{n}\,(\mu_a - \mu_o)}{\sigma}\,> \frac{t_{(1-\alpha, n-1)}}{\sqrt{n-1}}\,\sqrt{\chi^2_{n-1}}\,\,|\mu=\mu_a\Big)$.

Note that $\frac{(\mu_a - \mu_o)}{\sigma}$ is the *effect size*. We don't really have to know $\mu_a$: the effect size (or standardized effect size) is all we need. 

For the introduction of the $\Large \chi^2$ refer to:



<a href="https://math.stackexchange.com/questions/1386238/proof-that-frac-displaystyle-sum-x-1n-x-barx2-sigma2-sim">Proof of Chi Square distribution of ratio of $\sim s^2/\sigma^2$</a>. And remember:

$s^2=\frac{\sum(X-\bar{X})^2}{n-1}$.


<br>

Since the last equations involve more complex (bivariate) calculations, the power calculation can be achieved via Monte Carlo simulation:

```{r}
simuls <- 1e5         # Number of simulations
n <- 20               # Sample size 
sigma <- 5            # Standard deviation
mu_0 <- 25            # The mean we assume under Ho
mu_a <- 28            # The mean under Ha
Z  <- rnorm(simuls)   # Part of the inequality above
chisqr <- rchisq(simuls, df = n - 1)
t <- qt(.95, n - 1)
# The power is:
mean(Z + sqrt(n) * (mu_a - mu_0) / sigma > t / sqrt(n - 1) * sqrt(chisqr))
```

Compare to built-in formulas (equivalent to `sample.prop.test` for proportions):

```{r}
power.t.test(n = 20, delta = mu_a - mu_0, sd = sigma, type = "one.sample", alt = "one.sided")
```


<br><br>
RELATIONSHIPS:

1. Power goes up as $\alpha$ is larger.

2. Power of a one-sided test is greater than the power of the associated two-sided test - just think of it in terms of smaller $\alpha$ cuts ($\alpha/2$) 

3. Power goes up the further $\mu_a$ gets away from $\mu_o$.

4. Power goes up as $n$ goes up.

---

<a href="http://rinterested.github.io/statistics/index.html">Home Page</a>
