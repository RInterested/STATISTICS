<br>
<a href="http://rinterested.github.io/statistics/index.html">
<img HEIGHT="20" WIDTH="80" src="https://cloud.githubusercontent.com/assets/9312897/10556783/a27a26fa-745c-11e5-9b1a-2d5bd737387a.PNG"></a>


###SAMPLE TEST of two INDEPENDENT GROUPS:

<br><br>

$H_o: \mu_1=\mu_2$ while $\mu_1\neq \mu_2$. We can also test $\mu_1 \geq mu_2$ and $\mu_2 \geq mu_1$.

It's convenience to assume a normal variance and utilize a test statistic as follows:

test statistic = $\Large \frac{\bar X - \bar Y}{S_p\,\sqrt{\frac{1}{n_x} + \frac{1}{n_y}}}$. $S_p$ is the *pooled* standard deviation across both samples. It is the mean of *variances* - not standard deviations - and then square rooting: $\large S_p=\sqrt{SD_x^2+SD_y^2}$. 

It follows a $t$ distribution with $n_x + n_y - 2$ degrees of freedom.

If the assumption of common variance is not warranted, the test will be:

test statistic = $\Large \frac{\bar X - \bar Y}{\sqrt{\frac{SD_x^2}{n_x}+\frac{SD_y^2}{n_y}}}$.

This follows a $t$ distribution if $X_i$ and $Y_i$ are normally distributed.

The degrees of freedom are calculated as:

degrees of freedom = $\Large \frac{(S_x^2/n_x + S_y^2/n_y)^2}{\frac{(S_x^2/n_x)^2}{n_x-1}+\frac{(S_y^2/n_y)^2}{n_y-1}}$

---

<a href="http://rinterested.github.io/statistics/index.html">Home Page</a>