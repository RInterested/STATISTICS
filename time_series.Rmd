<br>
<a href="http://rinterested.github.io/statistics/index.html">
<img HEIGHT="20" WIDTH="80" src="https://cloud.githubusercontent.com/assets/9312897/10556783/a27a26fa-745c-11e5-9b1a-2d5bd737387a.PNG"></a>
<br><br>


###TYPES OF TIME SERIES:
<br>
    
#####**WHITE NOISE:**

$\large y_t = \epsilon_t$

Sequence of identically distributed variables $\epsilon_i$ with $\epsilon_i \sim N(0,\sigma^2)$:

```{R,fig.width = 7, fig.height = 3}
set.seed(2)
plot.ts(rnorm(100), col="tan4", ylab="white noise")
abline(h=0, col="red3", lty=2)
```

#####**RANDOM WALK:**

$\large y_t = y_{t-1}+\epsilon_t=\epsilon_t+\epsilon_{t-1}+\cdots+\epsilon_1$

```{R,fig.width = 7, fig.height = 3}
plot.ts(cumsum(rnorm(100)), col="tan2", ylab="random walk")
abline(h=0, col="red3", lty=2)
```

#####**AUTOREGRESSIVE 1 or AR(1):**

$\large y_t = \color{red}{\phi}\, y_{t-1}+c+\epsilon_t$

When $\phi < 1$ the series is "covariance stationary". Notice how the influence of the immediate prior position will be, to a certain extent, countered by the effect of $\phi$: the larger $\phi$ is the closer `AR` will be to a random walk; and the smaller it is, the more similar to white noise.

Leaving the constant $c=1$, and set $\phi=0.6$, here is an example:

```{R,fig.width = 7, fig.height = 3}
plot.ts(arima.sim(n=100,list(ar=0.6),innov=rnorm(100)), col="chocolate", ylab="AR(1)")
abline(h=0, col="red3", lty=2)
```

<br>


---

<a href="http://rinterested.github.io/statistics/index.html">Home Page</a>
