<br>
<a href="http://rinterested.github.io/statistics/index.html">
<img HEIGHT="20" WIDTH="80" src="https://cloud.githubusercontent.com/assets/9312897/10556783/a27a26fa-745c-11e5-9b1a-2d5bd737387a.PNG"></a>
<br><br>

##ROC curves and AUC:

There are reference answers on-line [here](https://www.unc.edu/courses/2010fall/ecol/563/001/docs/lectures/lecture21.htm) [here](http://stats.stackexchange.com/q/14153/67822), [here](http://stats.stackexchange.com/a/85413/67822) and [here](http://stackoverflow.com/q/23131897/4089351).


DEFINITIONS:

$\text{Sensitivity or TP Rate} = \frac{TP}{TP\, +\, FN}$

$\text{Specificity} = \frac{TN}{TN\, +\, FP}$

$\text{FP Rate or Fall-out} = \frac{FP}{TN\, +\, FP} = 1 - \text{Specificity}$

An accuracy of 100% means that the measured values are exactly the same as the given values:

$\text{Accuracy} = \frac{TP\, +\, TN}{TP\, +\, TN\, +\, FP\, +\, FN}$

$\text{Precision or PPV} = \frac{TP}{TP\, +\, FP}$

$\text{NPV} = \frac{TN}{TN\, +\, FN}$

---

Utilizing the PSA antigen data from [here](http://research.fhcrc.org/content/dam/stripe/diagnostic-biomarkers-statistical-center/files/psa2b.csv), where `fpsa` stands for "free PSA" and `tpsa` stands for "total PSA". There are repeated measures in time `t` at different `age`-s. The outcome is `d` and is coded as `0` or `1`:

```{r, warning = F, message=FALSE}
library(gsubfn)
library(sqldf)
library(tcltk)
library(pROC)
library(ROCR)
library(Epi)
library(gsheet)
```

The following is the dataset from a an age-matched case-control study: each diagnosed case was assigned a control matched to case by date of birth. There are 70 non diagnosed and 71 diagnosed:

```{r}
data = read.csv(text = gsheet2text('https://docs.google.com/spreadsheets/d/1ba1IYjX79EEmgBmsEzZgNs6Joe4v-SECWZUhbfhewhc/edit?usp=sharing', format ='csv'))
data = sqldf("select id, d, min(t), fpsa, tpsa, age from 'data'\n group by id")
data$age_group <- cut(data$age, breaks = c(45,55,65,75), labels = c("(45,55]","(55,65]","(65,75]"))
colnames(data)[2] = "outcome"
head(data)
```

Generating ROC curves with pROC:

```{r, fig.width=6, fig.height=4, message=FALSE}
# With total PSA:

r = roc(data$outcome, data$tpsa)
plot.roc(r, print.auc=TRUE, auc.polygon=TRUE, auc.polygon.col=rgb(.3,0,.8,0.2), print.thres=TRUE)
plot.roc(smooth(r), add=TRUE, col=2)
```

Notice that the thresholds used to construct the ROC plot, together with the calculated sensitivities and specificities are stored in `roc`:

```{r}
rock = pROC::roc(data$outcome, data$tpsa)
str(rock)

# Let's take a peek under the hood:

roc_scaffolding = data.frame(rock$thresholds, rock$sensitivities, rock$specificities)
head(roc_scaffolding)
```

In addition to the PSA we can stratify by patient's age:

```{r, message = F, fig.width=6, fig.height=3}
# With age groups:

plot.roc(x = data$outcome[data$age_gr == "(45,55]"], 
      predictor = data$tpsa[data$age_gr == "(45,55]"], 
      print.auc = TRUE, col = "green", print.auc.col = "green", 
      print.auc.y = 0.97, print.auc.x = 0.5)

plot.roc(x = data$outcome[data$age_gr == "(55,65]"], 
      predictor = data$tpsa[data$age_gr == "(55,65]"], 
      print.auc = TRUE, col = "blue", print.auc.col = "blue", add = TRUE, 
      print.auc.y = 0.82, print.auc.x = 0.7)

plot.roc(x = data$outcome[data$age_gr == "(65,75]"], 
      predictor = data$tpsa[data$age_gr == "(65,75]"], 
      print.auc = TRUE, col = "red", add = TRUE, print.auc.col = "red", 
      print.auc.y = 0.7, print.auc.x = 0.8)
```

And with ROCR:

```{r, fig.width=5, fig.height=3}
# With ROCR:
pred <- prediction(data$tpsa, data$outcome)
perf <- performance(pred, "tpr", "fpr")
# performance metrics TPR: True Positive Ratio FPR: False Positive Ratio
plot(perf, col = "green")
abline(0, 1, col = "grey")
auc <- performance(pred, "auc")
legend("bottomright", paste(round(as.numeric(auc@y.values), digits = 2)), col = c("green"), pch = c(3))
```

---

Alternatively, the `Epi` package can be used. In this case we are dealing with predicting the clinical [outcome in patients with subarachnoid hemorrage](http://link.springer.com/article/10.1007%2Fs00134-009-1641-y).

```{r}
data(aSAH)
head(aSAH)
rock = ROC(form = outcome ~ s100b, data=aSAH, plot = "ROC", MX = T)
```

Notice the values in the $18$-th row of the `ROC$res` printout - they are the values printed on plot above as `lr.eta` values:

```{r}
rock$res[18,]
```    

The ***maximized sum threshold or MST*** or the [**probability** of the outcome](http://rinterested.github.io/statistics/logistic_regression.html) is the `lr.eta` - in other words, the sigmoid function:



<br>
$$\Large \mathbb{E}[Y_i|X_i]=\frac{1}{1 + e^{-(\beta_0+\beta_1\times\text{s100b})}}$$
<br>

```{r, fig.width=6, fig.height=5}
rc <- ROC(form = outcome ~ s100b, data=aSAH, plot="sp") # Saving the ROC for later
ROC(form = outcome ~ s100b, data=aSAH, plot="sp" ) # Getting the ROC plot
# The following lines just literally color the black lines just printed:
lines(rc$res$lr, rc$res$spec, lwd = 2, type="s", col="red") #specificity
lines(rc$res$lr, rc$res$sens, lwd = 2, type="s", col="green") # sensitivity
lines(rc$res$lr, rc$res$pvp,  lwd = 2, type="s", col="orange") # pvp
lines(rc$res$lr, rc$res$pvn,  lwd = 2, type="s", col="magenta") # pvn
```


The maximal combination of sensitivity and specificity is given by:

```{r}
## optimal combination of sensitivity and specificity:

which.max(rowSums(rc$res[, c("sens", "spec")])) # Again the same value from row 18!
```

This is not the way a cut-off value is selected to report the result of a test as positive in clinical practice. Utilities (loss/cost) are needed to solve for the optimum cutoff on predicted risk." See comments [here](http://stats.stackexchange.com/a/67563/67822). 

Given that the parameters of the logistic regression are...

```{r}
rc$lr
```

this "optimal sensitivity/specificity" value in row 18 corresponds to:

$$\large 0.30426295405785 =\frac{1}{1+e^{-(-1.759+4.904\times \text{s100b})}}$$

and

$$\large \text{s100b}= 0.1900327$$

A plausible value of `s100b`:

```{r}
summary(aSAH$s100b) # Remember that not all values are used as cutoff points.
```

that will optimize sensitivity and specificity.

If we wanted to get the [cutoff points](http://stackoverflow.com/a/38532555/4089351), 
we'd have to use `sort(unique(aSAH))`. Let's see the value in position $18$...

```{r}
(points = c("Inf",sort(unique(aSAH$s100b))))[18]
```

<br>

#### MANUAL REPRODUCTION:

<br>
```{r, warning=F, message=FALSE}
data("aSAH")
(data <- aSAH[1:5,]) # We take only the first x rows - for instance 5
contrasts(data$outcome)
fit <- glm(outcome ~ s100b, data, family = "binomial") # This is the logistic regression that we will use as a predictor.
```

---

[ODDS RATIOS:](https://drive.google.com/file/d/0Bwl-HpVJ_5PeVE5BTU5QVUlxRGs/view?usp=sharing)

```{r, warning=F, message=FALSE}

exp(coef(fit))
exp(confint(fit))
```

---

PROBABILITIES:

PROBABILITIES given again by the sigmoid function:


$$\Large \color{green}{\text{p(Y = 1)}} = \frac{\color{blue}{\text{odds(Y=1)}}}{1\,+\,\color{blue}{\text{odds(Y=1)}}}=\frac{e^{\,\beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p}}{1 \,+\,e^{\,\beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p}}=\frac{1}{1 \,+\,e^{-(\,\beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p)}}$$

In a `glm()` (logistic regression) model, `predict()` simply gives you the LINEAR EQUATION ($\beta_0 + \beta_1 x_1 + \cdots + \beta_p x_p$).

```{r, warning=F, message=FALSE}
probabilities = exp(predict(fit)) / (  1 + exp(predict(fit))  ) 
```

These are the predicted probabilities (not the odds or the results of the logistic regression) for each value of s100b in the dataset.

Let's get the thresholds from the pROC package:

```{r, warning=F, message=FALSE}
(threshold = roc(data$outcome, data$s100b)$thresholds) 
```

Here we have them... Compare them to s100b... Parallel, but not quite:

```{r, warning=F, message=FALSE}
sort(data$s100b)
```

Let's add the predicted probabilities:

```{r}
data$probabilities <- probabilities

# and order the dataset just to take a peek at what it looks like...

(data[with(data, order(s100b)), ])

# Now let's what happens with different cutoff points...

cut <- rep(0, length(threshold)) # Establishing cutoff points empty vector
for (i in 1:length(threshold)){
cut[i] <- exp(predict(fit,data.frame(s100b=threshold[i]))) / (1 + exp(predict(fit,data.frame(s100b=threshold[i]))))
}
cut
```

The cuts are the different probabilities of having a good outcome based on the `s100b` theresholds. We have to decide what probability is "high enough" to classify all values with a higher probability as "POOR" outcome. Sometimes we'll be right; others wrong - it is a "supervised" learning process.

These are going to be the cutoff points:

```{r}
cut[is.na(cut)] <- 1.01 * max(data$probabilities) # These is to get rid of NA's.
cut
```

* For `cut[1] = 0`, all outcomes predicted as "Poor" (`1`): 
$\text{sens} = \frac{1\text{TP}}{1\text{ "Poor"}}=1/1$, $\text{spec} = \frac{0\text{TN}}{4\text{"Good"}}=0/4$

* For `cut[2] = 0.02880979`, there will $4$ predicted as "Poor" (`1`):
$\text{sens} = \frac{1\text{TP}}{1\text{"Poor"}}=1/1$, $\text{spec} = \frac{1\text{TN}}{4\text{"Good"}}=1/4$

* For `cut[3] = 0.1639541`, there will $3$ predicted as "Poor" (`1`):
$\text{sens} = \frac{1\text{TP}}{1\text{"Poor"}}=1/1$, $\text{spec} = \frac{2\text{TN}}{4\text{"Good"}}=2/4$

* For `cut[4] = 0.3122394`, there will $1$ predicted as "Poor" (`1`):
$\text{sens} = \frac{0\text{TP}}{1\text{"Poor"}}=0/1$, $\text{spec} = \frac{3\text{TN}}{4\text{"Good"}}=3/4$

* For `cut[5] = 0.36256518`, there will $0$ predicted as "Poor" (`1`):
$\text{sens} = \frac{0\text{TP}}{1\text{"Poor"}}=0$, $\text{spec} = \frac{4\text{TN}}{4\text{"Good"}}=4/4$

Coordinates then are:

$(1,0)$, $(1, 1/4)$, $(1, 1/2)$, $(0,3/4)$, $(0,1)$

<img HEIGHT="400" WIDTH="400" src="https://cloud.githubusercontent.com/assets/9312897/17070019/b7ed3494-5027-11e6-843e-89e4c2950dbe.png">
<br>

---

<br>

If the probabilities of "success"" (outcome 1 or, most commonly, "disease") predicted by the logistic regression order the values perfectly along the actual presence of "success", we could end up with a system like:

<br>
<img HEIGHT="700" WIDTH="800" src="https://cloud.githubusercontent.com/assets/9312897/13262903/3dd94fe8-da35-11e5-9690-fcf7541c5cbf.png">
<br>

In contradistinction, in a really bad test the predicted probabilities would bear no relation to the actual presence of the outcome, and the ROC curve would form a perfect diagonal:

<br>
<img HEIGHT="700" WIDTH="800" src="https://cloud.githubusercontent.com/assets/9312897/13262887/2a45b4e4-da35-11e5-9ae1-4307c7edfe26.png">
<br>

<br>
In general, though, the shape of an ROC curve will tend to be something like:

<br>
<img HEIGHT="700" WIDTH="800" src="https://cloud.githubusercontent.com/assets/9312897/13266022/08c94e98-da44-11e5-8ace-15a74052bc64.png">
<br>


<br>
```{r, message =F, warning = F}
# Let's automate:

data$outcome <- as.numeric(data$outcome) - 1
data[with(data, order(probabilities)), ]

positive <- 0
negative <- 0
tru_pos <- 0
tru_neg <- 0
for (i in 1:length(cut)){
sum(data$outcome)
positive[i] <- nrow(data[data$probabilities > cut[i], ])
negative[i] <- nrow(data) - positive[i]

# tru_pos will be the sum of the actual "1" or "successes" on the rows with values in the predictor function higher than the cutoff point:

tru_pos[i]  <- sum(data[data$probabilities > cut[i], ]$outcome)

# tru_neg will be the sum of the actual "1" or "successes" on the rows with values in the predictor function lower than the cutoff point (these are FN) subtracted from all the negatives:

tru_neg[i]  <- negative[i] - sum(data[data$probabilities < cut[i], ]$outcome)
}

sens   <- tru_pos / sum(data$outcome)
specif <- tru_neg / (length(data$outcome) - sum(data$outcome))
(rock = cbind(cut, positive, negative,tru_pos,tru_neg, sens, specif))

par(mfrow=c(1,2))

# What we want:

plot.roc(data$outcome, data$s100b, 
    auc.polygon = TRUE, 
    auc.polygon.col=rgb(.35,0.31,0.61, alpha = 0.4), 
    auc.polygon.border=rgb(.35,0.31,0.61, 0.4))


# what we got will be superimposed as a red line on top of the ROC generated by R:

plot.roc(data$outcome, data$s100b,lwd=15,col="gray75")
rock <- rbind(rep(0,7), rock)
lines(rock[,6] ~ rock[,7],xlim=rev(range(rock[,7])), lwd = 2,col ="red") 
polygon(rock[,6] ~ rock[,7], xlim=rev(range(rock[,7])), col=rgb(.9,0.1,0.1, alpha = 0.4))
segments(1,0,0,1)
segments(1,0,0,1)
```

Now for the entire dataset:

```{r, echo=F, message=F, warning = F}
data <- aSAH
fit <- glm(outcome ~ s100b, data, family = "binomial")
threshold <- function(predict, response) {
  r <- roc(response, predict)
  r$thresholds
}
threshold <- threshold(data$s100b, data$outcome)
data$predicted <- exp(predict(fit)) / (  1 + exp(predict(fit))  )
cut <- rep(0, length(threshold)) # Establishing cutoff points
for (i in 1:length(threshold)){
cut[i] <- exp(predict(fit,data.frame(s100b=threshold[i]))) / (1 + exp(predict(fit,data.frame(s100b=threshold[i]))))
}
cut[is.na(cut)] <- 1.01 * max(data$predicted)
data$outcome <- as.numeric(data$outcome) - 1

positive <- 0
negative <- 0
tru_pos <- 0
tru_neg <- 0
for (i in 1:length(cut)){
sum(data$outcome)
positive[i] <- nrow(data[data$predicted > cut[i], ])
negative[i] <- nrow(data) - positive[i]
tru_pos[i]  <- sum(data[data$predicted > cut[i], ]$outcome)
tru_neg[i]  <- (negative[i] - sum(data[data$predicted < cut[i], ]$outcome)) 
               + (positive[i] - tru_pos[i])
}

sens <- tru_pos/sum(data$outcome)
specif <- tru_neg / (length(data$outcome) - sum(data$outcome))
rock = cbind(cut, positive, negative,tru_pos,tru_neg, sens, specif)

par(mfrow=c(1,2))

# What we want:

plot.roc(data$outcome, data$s100b, 
    auc.polygon = TRUE, 
    auc.polygon.col=rgb(.35,0.31,0.61, alpha = 0.4), 
    auc.polygon.border=rgb(.35,0.31,0.61, 0.4))


# what we got will be superimposed as a red line on top of the ROC generated by R:

plot.roc(data$outcome, data$s100b,lwd=15,col="gray75")
rock <- rbind(rep(0,7), rock)
lines(rock[,6] ~ rock[,7],xlim=rev(range(rock[,7])), lwd = 2,col ="red") 
polygon(rock[,6] ~ rock[,7], xlim=rev(range(rock[,7])), col=rgb(.9,0.1,0.1, alpha = 0.4))
segments(1,0,0,1)
segments(1,0,0,1)
```

We can calculate the AUC manually:

```{r}
AUC = function(sens,specif){
    partitions <- 1 / length(threshold[2:(length(threshold) - 1)])
    rect <- partitions * sens[2:((length(sens) - 1) )]
    triang <- partitions * sens[2:((length(sens) - 1) )] / 2
    sum(rect) + sum(triang)
}
AUC(sens,specif)
roc(data$outcome, data$s100b, print.auc = T)

```
---

<a href="http://rinterested.github.io/statistics/index.html">Home Page</a>
