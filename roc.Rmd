<br>
<a href="http://rinterested.github.io/statistics/index.html">
<img HEIGHT="20" WIDTH="80" src="https://cloud.githubusercontent.com/assets/9312897/10556783/a27a26fa-745c-11e5-9b1a-2d5bd737387a.PNG"></a>
<br><br>

##ROC curves and AUC:

This post draws from the material here: [here](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=21&cad=rja&uact=8&ved=0ahUKEwinjdHJ_oLLAhWBmR4KHTY8Axs4FBAWCBswAA&url=http%3A%2F%2Fr-es.org%2Fdl1192&usg=AFQjCNFxRXWxz4SWoOgzIFn_jzIAGKxNsQ&sig2=ELFkO23EgdBPH_6GjEkVvA).

There are reference answers on-line [here](https://www.unc.edu/courses/2010fall/ecol/563/001/docs/lectures/lecture21.htm) [here](http://stats.stackexchange.com/q/14153/67822), [here](http://stats.stackexchange.com/a/85413/67822) and [here](http://stackoverflow.com/q/23131897/4089351).


DEFINITIONS:

$\text{Sensitivity or TP Rate} = \frac{TP}{TP\, +\, FN}$

$\text{Specificity} = \frac{TN}{TN\, +\, FP}$

$\text{FP Rate or Fall-out} = \frac{FP}{TN\, +\, FP} = 1 - \text{Specificity}$

An accuracy of 100% means that the measured values are exactly the same as the given values:

$\text{Accuracy} = \frac{TP\, +\, TN}{TP\, +\, TN\, +\, FP\, +\, FN}$

$\text{Precision or PPV} = \frac{TP}{TP\, +\, FP}$

$\text{NPV} = \frac{TN}{TN\, +\, FN}$

---

Utilizing the PSA antigen data from [here](http://research.fhcrc.org/content/dam/stripe/diagnostic-biomarkers-statistical-center/files/psa2b.csv), where `fpsa` stands for "free PSA" and `tpsa` stands for "total PSA". There are repeated measures in time `t` at different `age`-s. The outcome is `d` and is coded as `0` or `1`:

```{r,echo=F, warning = F,message=FALSE}
library(gsubfn)
library(sqldf)
library(tcltk)
library(pROC)
library(ROCR)
library(Epi)
library(gsheet)
data <- read.csv(text = 
gsheet2text('https://docs.google.com/spreadsheets/d/1ba1IYjX79EEmgBmsEzZgNs6Joe4v-SECWZUhbfhewhc/edit?usp=sharing',
format ='csv'))
data <- sqldf("select id, d, min(t), fpsa, tpsa, age from 'data'\n group by id")
# This study is an age-matched case-control design: each diagnosed case was assigned a control matched to case by date of birth. There are 70 non diagnosed and 71 diagnosed:
data$age_group <- cut(data$age, breaks = c(45,55,65,75), labels = c("(45,55]","(55,65]","(65,75]"))
colnames(data)[2] = "outcome"
head(data)
```


Generating ROC curves with pROC:

```{r}
# With total PSA:
par(mfrow=c(1,2))
plot.roc(data$outcome, data$tpsa, print.auc = TRUE, smooth=F)
plot.roc(data$outcome, data$tpsa, print.auc = TRUE, smooth=T)
```

Notice that the cutoff or threshold values utilized to build up the plot can be [extracted as](http://stackoverflow.com/a/35115425/4089351):

```{r}
threshold <- function(predict, response) {
    r <- pROC::roc(response, predict)
    r$thresholds
}
threshold(data$tpsa, data$outcome)
```

Instead of the PSA we can consider the patient's age:

```{r, message = F,echo=F}
# With age groups:

plot.roc(x = data$outcome[data$age_gr == "(45,55]"], 
      predictor = data$tpsa[data$age_gr == "(45,55]"], 
      print.auc = TRUE, col = "green", print.auc.col = "green", 
      print.auc.y = 0.97, print.auc.x = 0.5)

plot.roc(x = data$outcome[data$age_gr == "(55,65]"], 
      predictor = data$tpsa[data$age_gr == "(55,65]"], 
      print.auc = TRUE, col = "blue", print.auc.col = "blue", add = TRUE, 
      print.auc.y = 0.82, print.auc.x = 0.7)

plot.roc(x = data$outcome[data$age_gr == "(65,75]"], 
      predictor = data$tpsa[data$age_gr == "(65,75]"], 
      print.auc = TRUE, col = "red", add = TRUE, print.auc.col = "red", 
      print.auc.y = 0.7, print.auc.x = 0.8)
```

And with ROCR:

```{r}
# With ROCR:
pred <- prediction(data$tpsa, data$outcome)
perf <- performance(pred, "tpr", "fpr")
# performance metrics TPR: True Positive Ratio FPR: False Positive Ratio
plot(perf, col = "green")
abline(0, 1, col = "grey")
auc <- performance(pred, "auc")
legend("bottomright", paste(round(as.numeric(auc@y.values), digits = 2)), col = c("green"), pch = c(3))
```

---

Alternatively, the `Epi` package can be used. In this case we are dealing with predicting the clinical [outcome in patients with subarachnoid hemorrage](http://link.springer.com/article/10.1007%2Fs00134-009-1641-y).

```{r}
data(aSAH)
head(aSAH)
ROC(form = outcome ~ s100b, data=aSAH, plot = "ROC", MX = T)
```

Looking into the structure of `ROC`... we see that it is a list containing a data frame `res` defined as:

      res	
      dataframe with variables sens, spec, pvp, pvn and name of the test   variable. The latter is the unique values of test or linear predictor from the logistic regression in ascending order with -Inf prepended. Since the sensitivity is defined as P(test>x)|status=TRUE, the first row has sens equal to 1 and spec equal to 0, corresponding to drawing the ROC curve from the upper right to the lower left corner.

The first column is the same as `lr.eta`, `eta` being the ***maximized sum threshold or MST*** or the [**probability** of the outcome](http://rinterested.github.io/statistics/logistic_regression.html):

<br>
$$\Large \mathbb{E}[Y_i|X_i]=\frac{1}{1 + e^{-(\beta_0+beta_1\times\text{s100b})}}$$
<br>

```{r}
rc <- ROC(form = outcome ~ s100b, data=aSAH, plot="sp" )
ROC(form = outcome ~ s100b, data=aSAH, plot="sp" )
lines(rc$res$lr,rc$res$spec, lwd = 2, type="s", col="red") #specificity
lines(rc$res$lr,rc$res$sens, lwd = 2, type="s", col="green") # sensitivity
lines(rc$res$lr,rc$res$pvp, lwd = 2, type="s", col="orange") # pvp
lines(rc$res$lr,rc$res$pvn, lwd = 2, type="s", col="magenta") # pvn
(rc)$res[1:5,]
```


The maximal combination of sensitivity and specificity is given by:

```{r}
## optimal combination
opt <- which.max(rowSums(rc$res[, c("sens", "spec")]))
## optimal cut-off point 
rc$res$lr.eta[opt]


which.max(rowSums(rc$res[, c("sens", "spec")]))
```

... although this is not the way a cut-off value is selected to report the result of a test as positive, which would be "determined by the probability of getting a more extreme value than that in a normal population. Utilizing this a clinical cut-off from normal to abnormal would be inconsistent with optimal decision making. It is simply not appropriate to seek cutoffs on inputs. Optimum decisions are made using no cutoffs at all, or, if needed before decision time, by making cutoffs on the predicted probabilities. Utilities (loss/cost) are needed to solve for the optimum cutoff on predicted risk." See comments [here](http://stats.stackexchange.com/a/67563/67822). 

The value in row $\small 18$:

```{r}
(rc)$res[18,]
```

Given that the parameters of the logistic regression are...


```{r}
rc$lr
```


this corresponds to:

$$\Large 0.30426295405785 =\frac{1}{1+e^{-(-1.759+4.904\times \text{s100b})}}$$

and

$$\Large \text{s100b}= 0.1900327$$

A plausible value of `s100b`:

```{r}
aSAH$s100b
```

that will optimize sensitivity and specificity.

If we wanted to get the cutoff points we'd have to use

```{r}
threshold(aSAH$s100b, aSAH$outcome)
```

<br>

#### MANUAL REPRODUCTION:

<br>
```{r, warning=F, message=FALSE}
data("aSAH")
data <- aSAH[1:5,] # We take only the first x rows - for instance 5
fit <- glm(outcome ~ s100b, data, family = "binomial") # This is the logistic regression that we will use as a predictor.
```


[ODDS RATIOS:](https://drive.google.com/file/d/0Bwl-HpVJ_5PeVE5BTU5QVUlxRGs/view?usp=sharing)

```{r, warning=F, message=FALSE}
exp(coef(fit))
exp(confint(fit))
```

PROBABILITIES:

```{r, warning=F, message=FALSE}
exp(predict(fit)) / (  1 + exp(predict(fit))  ) # These are the predicted probabilities (not the odds or the results of the logistic regression) for each value of s100b in the dataset

# let's get the thresholds from the pROC package:
threshold <- function(predict, response) {
  r <- roc(response, predict)
  r$thresholds
}

(threshold <- threshold(data$s100b, data$outcome)) # Here we have them... Compare them to s100b... Parallel, but not quite:

sort(data$s100b)

# Let's add the predicted values:;

data$predicted <- exp(predict(fit)) / (  1 + exp(predict(fit))  ) 

# and order the dataset just to take a peek at what it looks like...

(data[with(data, order(s100b)), ])

# Now let's what happens with different cutoff points...

cut <- rep(0, length(threshold)) # Establishing cutoff points
for (i in 1:length(threshold)){
cut[i] <- exp(predict(fit,data.frame(s100b=threshold[i]))) / (1 + exp(predict(fit,data.frame(s100b=threshold[i]))))
}

# These are going to be the cutoff points:

cut
cut[is.na(cut)] <- 1.01 * max(data$predicted) # These is to get rid of NA's.

# for cut[1] = 0, there will be zero poor - sens 1/1, sp 0/4
# for cut[2] = 0.02880979, sens = 1corr as pos/ 1pos, specificity 1correct as neg/4negs
# for cut[3] = 0.1639541, there will be one poor - sens 1; sp = 2/4 = 1/2
# for cut[4] = 0.3122394, there will be zero poor - sen=0; sp =3/4
# for cut[5] = NaN, I don't know... inf? then sens=0; sp = 1

# Coordinates then are:
# (1,0), (1, 1/4), (1, 1/2), (0,3/4), (0,1)
```

<br>
If the probabilities of "success"" (outcome 1 or, most commonly, "disease") predicted by the logistic regression order the values perfectly along the actual presence of "success", we could end up with a system like:

<br>
<img HEIGHT="700" WIDTH="800" src="https://cloud.githubusercontent.com/assets/9312897/13240106/bb4e0668-d9ad-11e5-8176-a51fd5a08295.png">
<br>

In contradistinction, in a really bad test the predicted probabilities would bear no relation to the actual presence of the outcome, and the ROC curve would form a perfect diagonal:

<br>
<img HEIGHT="700" WIDTH="800" src="https://cloud.githubusercontent.com/assets/9312897/13240097/a0b0eb68-d9ad-11e5-863c-e4ac8d0b12a1.png">
<br>


<br>
```{r, message =F, warning = F}
# Let's automate:

data$outcome <- as.numeric(data$outcome) - 1
data[with(data, order(predicted)), ]

positive <- 0
negative <- 0
tru_pos <- 0
tru_neg <- 0
for (i in 1:length(cut)){
sum(data$outcome)
positive[i] <- nrow(data[data$predicted > cut[i], ])
negative[i] <- nrow(data) - positive[i]

# tru_pos will be the sum of the actual "1" or "successes" on the rows with values in the predictor function higher than the cutoff point:

tru_pos[i]  <- sum(data[data$predicted > cut[i], ]$outcome)

# tru_neg will be the sum of the actual "1" or "successes" on the rows with values in the predictor function lower than the cutoff point (these are FN) subtracted from all the negatives:

tru_neg[i]  <- negative[i] - sum(data[data$predicted < cut[i], ]$outcome)
}

sens   <- tru_pos / sum(data$outcome)
specif <- tru_neg / (length(data$outcome) - sum(data$outcome))
(rock = cbind(cut, positive, negative,tru_pos,tru_neg, sens, specif))

par(mfrow=c(1,2))

# What we want:

plot.roc(data$outcome, data$s100b, 
    auc.polygon = TRUE, 
    auc.polygon.col=rgb(.35,0.31,0.61, alpha = 0.4), 
    auc.polygon.border=rgb(.35,0.31,0.61, 0.4))


# what we got will be superimposed as a red line on top of the ROC generated by R:

plot.roc(data$outcome, data$s100b,lwd=15,col="gray75")
rock <- rbind(rep(0,7), rock)
lines(rock[,6] ~ rock[,7],xlim=rev(range(rock[,7])), lwd = 2,col ="red") 
polygon(rock[,6] ~ rock[,7], xlim=rev(range(rock[,7])), col=rgb(.9,0.1,0.1, alpha = 0.4))
segments(1,0,0,1)
segments(1,0,0,1)
```

Now for the entire dataset:

```{r, echo=F, message=F, warning = F}
data <- aSAH
fit <- glm(outcome ~ s100b, data, family = "binomial")
threshold <- function(predict, response) {
  r <- roc(response, predict)
  r$thresholds
}
threshold <- threshold(data$s100b, data$outcome)
data$predicted <- exp(predict(fit)) / (  1 + exp(predict(fit))  )
cut <- rep(0, length(threshold)) # Establishing cutoff points
for (i in 1:length(threshold)){
cut[i] <- exp(predict(fit,data.frame(s100b=threshold[i]))) / (1 + exp(predict(fit,data.frame(s100b=threshold[i]))))
}
cut[is.na(cut)] <- 1.01 * max(data$predicted)
data$outcome <- as.numeric(data$outcome) - 1

positive <- 0
negative <- 0
tru_pos <- 0
tru_neg <- 0
for (i in 1:length(cut)){
sum(data$outcome)
positive[i] <- nrow(data[data$predicted > cut[i], ])
negative[i] <- nrow(data) - positive[i]
tru_pos[i]  <- sum(data[data$predicted > cut[i], ]$outcome)
tru_neg[i]  <- (negative[i] - sum(data[data$predicted < cut[i], ]$outcome)) 
               + (positive[i] - tru_pos[i])
}

sens <- tru_pos/sum(data$outcome)
specif <- tru_neg / (length(data$outcome) - sum(data$outcome))
rock = cbind(cut, positive, negative,tru_pos,tru_neg, sens, specif)

par(mfrow=c(1,2))

# What we want:

plot.roc(data$outcome, data$s100b, 
    auc.polygon = TRUE, 
    auc.polygon.col=rgb(.35,0.31,0.61, alpha = 0.4), 
    auc.polygon.border=rgb(.35,0.31,0.61, 0.4))


# what we got will be superimposed as a red line on top of the ROC generated by R:

plot.roc(data$outcome, data$s100b,lwd=15,col="gray75")
rock <- rbind(rep(0,7), rock)
lines(rock[,6] ~ rock[,7],xlim=rev(range(rock[,7])), lwd = 2,col ="red") 
polygon(rock[,6] ~ rock[,7], xlim=rev(range(rock[,7])), col=rgb(.9,0.1,0.1, alpha = 0.4))
segments(1,0,0,1)
segments(1,0,0,1)
```

---

<a href="http://rinterested.github.io/statistics/index.html">Home Page</a>
