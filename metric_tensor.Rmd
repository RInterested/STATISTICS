<br>
<a href="http://rinterested.github.io/statistics/index.html">
<img HEIGHT="20" WIDTH="80" src="https://cloud.githubusercontent.com/assets/9312897/10556783/a27a26fa-745c-11e5-9b1a-2d5bd737387a.PNG"></a>
<br><br>

###THE METRIC TENSOR:
<br>

<img width=700 src="https://cloud.githubusercontent.com/assets/9312897/22626987/0d62c42a-eb87-11e6-9e53-263ab8c1036a.png">

The **length or magnitude** of the vector $dS$ **in Cartesian coordinates** is given by:

$$dS^2=\left(dX^1\right)^2 + \left(dX^2\right)^2 + \left(dX^3\right)^2 + \cdots = \large \delta_{mn} \;\color{blue}{dX^m}\, dX^n\tag 1$$

Notice that the dummy indexes are set up to sum over. We start with $m=1$, and we see that all terms are going to be zero unless when $n=1$, in which case it will be $dX^1\, dX^1 = (dX^1)^2.$

But how to write the same for the curvilinear system?

We have to refer back to the following expression expressing a change of coordinate system at the beginning of the [notes on tensors](http://rinterested.github.io/statistics/tensors.html):

$$dy^n = \frac{\partial y^n}{\partial x^\color{blue}{m}} dx^{\color{blue}{m}} \tag{Einstein's convention}$$

In this case we have that the part in blue in Eq. 1 can be expressed as:

$$\color{blue}{dX^m}= \frac{\partial x^m}{\partial y^r} dy^r \tag2$$

Hence, Eq. 1 becomes,

$$dS^2 = \large \delta_{mn} \;dX^m\, dX^n= \large \underset{\text{METRIC TENSOR }\Large g^{(y)}_{\color{red}{rs}}}{\underbrace{\delta_{mn}\frac{\partial x^m}{\partial y^\color{red}{r}}\frac{\partial x^n}{\partial y^\color{red}{s}}}} \;dy^r\; dy^s$$

<br>

$$\huge \bbox[10px, border:2px solid aqua]{g^{(y)}_{\color{red}{rs}}=\delta_{mn}\frac{\partial x^m}{\partial y^\color{red}{r}}\frac{\partial x^n}{\partial y^\color{red}{s}}}\tag 3$$

So it seems to be the instrument that transforms from one set of coordinates to another and at the same time indicates when to actually measure the magnitude of the vector.

We write,

$$dS^2 = q^{(y)}_{rs}\,dy^r\,dy^s$$

If we were operating with both systems being curvilinear, the measure of the vector wouldn't be as simple in the $X$ system as before. We would have:

$$\large g^{(x)}_{mn}\,dx^m\,dx^n=g^{(y)}_{rs}\,dy^r\,dy^s$$

applying Eq. 2,

$$\large g^{(x)}_{mn}\frac{\partial x^m}{\partial y^r}\frac{\partial x^n}{\partial y^s}dy^r\,dy^s= g^{(y)}_{rs}\,dy^r\,dy^s$$

<br>

$$\large g^{(x)}_{mn}\frac{\partial x^m}{\partial y^r}\frac{\partial x^n}{\partial y^s} = g(y)_{(rs)}$$

which is a covariant transformation. So the matrix tensor does transform like a covariant tensor.

From [Tensors](http://rinterested.github.io/statistics/tensors.html):

$$\bbox[10px, border:2px solid aqua]{ \varepsilon_i =\frac{\partial \vec r}{\partial u^i}}$$

we have that a displacement vector $\vec r$ in a curvilinear system of coordinates:

<img width = 300 src = "https://cloud.githubusercontent.com/assets/9312897/22630116/b745ec62-ebc1-11e6-8576-bf66ba1d9e08.png">

$$\large d\vec r = \vec \varepsilon_1 d u^1 + \vec \varepsilon_2 d u^2 + \cdots = \vec \varepsilon_i du^i$$

<br>

$$\large dS^2 = d\vec r \cdot d\vec r$$

<br>

$$\large dS^2 = \vec e_i \,du^i \cdot \vec e_j\,du^j=\vec e_i \, \vec e_j \, du^i \, du^j$$

<br>

$$\large dS^2 = g_{ij}\, du^i\, du^2$$

which implies that the dot product of two tangent vectors is the **metric tensor**:


$$\huge\bbox[10px, border:2px solid blue]{\vec \varepsilon_i\vec \varepsilon_j = g_{ij}}\tag 4$$

Of note, for expressions in terms of COVARIANT COMPONENTS we have the CONTRAVARIANT FORM of the metric tensor:

$$\huge\bbox[10px, border:2px solid blue]{\vec \varepsilon^i\vec \varepsilon^j = g^{ij}}\tag {CONTRAVARIANT FORM}$$

---

NOTE: DO NOT CONFUSE WITH d$e_i\,e^j =\delta_i^j$ or $e^i\,e_j= \delta_j^i$ ([Eq. 11 under tensors](http://rinterested.github.io/statistics/tensors.html)), which simply expresses that tangent vectors are orthogonal to orthogonal vectors in the generalized curvilinear system.

---

Looking at spherical coordinates:

<img width=400 src = "https://cloud.githubusercontent.com/assets/9312897/22637882/9e6e98be-ec12-11e6-8025-227fa40333f1.png">

$$\vec r = \rho\, \cos(\phi) \vec {\hat i} + \rho\, \sin(\phi)\vec {\hat j} + z \vec {\hat k}$$

$$\vec e_\rho = \vec e_1 = \frac{\partial \vec r}{\partial \rho}= \cos(\phi) \vec {\hat i} + \sin(\phi) \, \vec{\hat j}$$

$$\vec e_\phi = \vec e_2 = \frac{\partial \vec r}{\partial \phi}= -\rho \sin(\phi) \vec {\hat i} + \rho\,\cos(\phi)\,\vec{\hat j}$$

$$\vec e_z = \vec e_3= \frac{\partial \vec r}{\partial z}= \vec{\hat k}$$

From Eq. 4, $g_{ij}= \vec e_i \ vec e_j$, we have 

$$\begin{matrix}\vec e_1\vec e_1&\vec e_1\vec e_2&\vec e_1\vec e_3\\
\vec e_2\vec e_1&\vec e_2\vec e_2&\vec e_2\vec e_3\\
\vec e_3\vec e_1&\vec e_3\vec e_2&\vec e_3\vec e_3
\end{matrix}$$

So let's take the element $g_{11}=(1,1)=(\vec e_1\vec e_1):$

$$g_{11}= \left( \cos(\phi) \vec {\hat i} + \sin(\phi ) \, \vec{\hat j}\right)\left( \cos(\phi) \vec {\hat i} + \sin(\phi) \, \vec{\hat j}\right)= \cos^2(\phi)+\sin^2(\phi)=1$$

Notice that $\vec {\hat i}\cdot \vec {\hat j}=0.$

Moving to $g_{12}=0$, which means that $g_{21}=0.$

What about $g_{22}=\left(-\rho \sin(\phi) \vec {\hat i} + \rho\,\cos(\phi)\,\vec{\hat j}\right)\left(-\rho \sin(\phi) \vec {\hat i} + \rho\,\cos(\phi)\,\vec{\hat j}\right)=\rho^2\sin^2(\phi)+\rho^2\cos^2(\phi)=\rho^2$

And $g_{23}=0$; $g_{13}=0$; and $g_{33}=1$

Hence the metric tensor for cylindrical coordinates is:

$$\begin{bmatrix}1&0&0\\0&\rho^2&0\\0&0&1 \end{bmatrix}$$

which makes sense, because we have orthogonal tangent vectors in this particular case, explaining that the only non-zero entries are in the diagonal. But in a more general curvilinear system, the tangent vectors will not be orthogonal to each other.

---

> RAISING AND LOWERING INDEXES:

Let's consider a vector $\vec A$ in contravariant $(\vec A = a^1\,\vec e_1 + a^2\,\vec e_2 + a^3\, \vec e_3+\cdots = a^i\,\vec e_i)$, and covariant coordinates $(\vec A = a_1\,\vec e^1 + a_2\,\vec e^2 + a_3\, \vec e^3+\cdots = a_i\,\vec e^i)$. Similarly, we have a vector $\vec B$ also expressed in terms of contra and covariant components.

We know that $e_i\,e^j =\delta_i^j$ or $e^i\,e_j= \delta_j^i$ ([Eq. 11 under tensors](http://rinterested.github.io/statistics/tensors.html)).

Taking the dot product of $\vec A$ and $\vec B$, we can get four different expressions:

>1. Contravariant components of A and B:

$$\vec A\vec B= a^ie_i\cdot b^je_j= a^ib^j e_i\cdot e_j = g_{ij}a^ib^j$$ with $g_{ij}$ being the covariant form of the tensor matrix.

>2. Covariant components of A and B:

$$\vec A\vec B= a_ie^i\cdot b_je^j= a_ib_j e^i\cdot e^j = g^{ij}a^ib^j$$ with $g^{ij}$ being the contravariant form of the tensor matrix.

>3. Covariant components of A and contravariant components of B:

$$\vec A\vec B= a_ie^i\cdot b^je_j= a_ib^j e^i\cdot e_j = \delta_j^i a_i b^j = a_ib^i$$ with $e^i\cdot e_j =\delta_j^i$ (see comment or note under Eq. 4 above).

>4. Contravariant components of A and covariant components of B:

$$\vec A\vec B= a^ie_i\cdot b_je^j= a^ib_j e_i\cdot e^j = \delta_i^j a^i b_j = a^ib_i$$


---

<a href="http://rinterested.github.io/statistics/index.html">Home Page</a>
