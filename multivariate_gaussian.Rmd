<br>
<a href="http://rinterested.github.io/statistics/index.html">
<img HEIGHT="20" WIDTH="80" src="https://cloud.githubusercontent.com/assets/9312897/10556783/a27a26fa-745c-11e5-9b1a-2d5bd737387a.PNG"></a>
<br><br>

###MULTIVARIATE GAUSSIAN:
<br>

The univariate Gaussian ($X \sim N(\mu, \sigma^2$) is:

$$f(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(x-\mu)^2\right), \forall \in \mathbb R.$$ 

The degenerate Gaussian has variance equal to $0$ and hence, $X(\omega)=\mu, \forall \omega \in \Omega.$

The multivariate Gaussian is defined for $X \in \mathbb R^n$ as any linear combination of univariate Gaussian distribution:

$a^T X = \sum_{i=1}^n a_i X_i$ for $\forall a \in \mathbb R^n.$

We will express it as $X\sim N(\mu,\Sigma)$, where $\mu$ is a vector in $\mathbb R^n$. The $\mathbb E(X_i)=\mu_i$; and the covariance matrix is an $n \times n$ positive semidefinite matrix, such that $\Sigma(X_i, X_j) = \Sigma_{ij}.$

A multivariate Gaussian is degenerated if the $det(\Sigma)=0.$

If the Gaussian distributions are independent, the covariance matrix is:

$$\Sigma = \begin{bmatrix}\sigma_1^2&0\\0&\sigma_2^2\end{bmatrix}$$

If the variance is $1$ for both Gaussians:

<img height="600" width="500" src="https://cloud.githubusercontent.com/assets/9312897/17905119/d6c63128-693f-11e6-930e-08c7302105a6.png">

If the variances are different, say $1$ and $4$:

<img height="600" width="500" src="https://cloud.githubusercontent.com/assets/9312897/17905528/4d70fdca-6941-11e6-8df2-1f4578a42d95.png">

This is the Matlab code:

```
pkg load 'statistics'
mu = [0,0]; %// data
sigma = [1 0; 0 4]; %// data
x = -5:.2:5; %// x axis
y = -5:.2:5; %// y axis

[X Y] = meshgrid(x,y); %// all combinations of x, y
Z = mvnpdf([X(:) Y(:)],mu,sigma); %// compute Gaussian pdf
Z = reshape(Z,size(X)); %// put into same size as X, Y
surf(X,Y,Z) %// ... or 3D plot
```

The density of the multivariate Gaussian is:

$$f(X) = \frac{1}{\sqrt{\vert2\pi\Sigma^2\vert}}\exp\left(-\frac{1}{2}(x-\mu)^T \,\Sigma^{-1}\,(x-\mu)\right)$$

$\vert2\pi\Sigma^2\vert= (2\pi)^n \times \text{det}(\Sigma)$ is the determinant of $2\pi\Sigma^2$.

$(x-\mu)^T \,\Sigma^{-1}\,(x-\mu)$ is a **quadratic form**. A quadratic form in linear algebra is of the form $x^TAx$, providing the formula for ellipsoids in higher dimensions.

---

Ellipsoids are of the form $x^2/a^2+y^2/b^2+z^2/c^2 = 1$:

<img height="600" width="500" src="https://cloud.githubusercontent.com/assets/9312897/17914054/f35715fa-696c-11e6-9a71-eca422b98985.png">

---

This is [Dr. Strang's example](https://youtu.be/vF7eyJ2g3kU) of a $3 \times 3$ positive definite matrix. What he calls "the good matrix":

$$A= \begin{bmatrix}2&-1&0\\-1&2&-1\\0&-1&2\end{bmatrix}$$

Proving that it is positive definite through the $x^TAx$ rule...

$$x^TAx=2x_1^2 + 2x_2^2 + 2x_3^2 - 2x_1x_2 - 2x_2x_3  > 0$$

we could complete the square to proof that the inequality is true.

We are in four dimensions, being that we have a function. But if we cut through this thing at height one, we get an ellipsoid (a lopsided football).

---

<a href="http://rinterested.github.io/statistics/index.html">Home Page</a>
