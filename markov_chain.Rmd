---
title: 'Markov chains'
output: 
  html_document:
    theme: readable
    includes:
      in_header: "favicon.html" 
    css: custom.css
---


### **NOTES ON STATISTICS, PROBABILITY and MATHEMATICS**

<a href="http://rinterested.github.io/statistics/index.html">
<img HEIGHT="40" WIDTH="50" src="logo.PNG"></a>

---

### Transition or Stochastic Matrices:

---

The objective of [Markov matrices](https://en.wikipedia.org/wiki/Stochastic_matrix) is to incorporate probability vectors so as to calculate the steady state distribution of proportions based on an initial state.

For example, if we know that a certain percentage of people leave the city for the suburbs every year, and a different proportion of city dwellers move to the suburbs, we can find out the percentage or number of people living in the city and suburbs one year from now:

---

 <img src="https://user-images.githubusercontent.com/9312897/33838012-2b845a68-de5c-11e7-9ab9-d46b8d60c2e4.png" width=500>
 
---
 
 $$\begin{bmatrix}
  & \text{City} & \text{Suburbs} \\
\text{City} & 0.88 & \color{red}{0.12}\\
\text{Suburbs} & \color{magenta}{0.05}
& 0.95\end{bmatrix}
\underbrace{\begin{bmatrix}\text{C}\\\text{S}\end{bmatrix}}_{\text{initial state}}=\underbrace{\begin{bmatrix}\text{C}\\\text{S}\end{bmatrix}}_{\text{state 1 yr later}}$$

---
 
 
#### [ABSORBING MARKOV CHAINS](https://en.wikipedia.org/wiki/Absorbing_Markov_chain):
<br>

From [this series of lectures](https://youtu.be/BsOkOaB8SFk).

An absorbing state in a transition MC is such that when it is entered, it becomes impossible to leave. They are identified as $1$'s in the diagonal matrix.

An absorbing MC, like a regular MC, tends to a limiting matrix by calculating powers of the transition matrix, $P.$ The presence of absorbing states does not guarantee a limiting matrix: for its to happen, the absorbing states have to be able to transition to absorbing states.

For instance, in the matrix

$$\tiny P=\begin{bmatrix} & A & B & C \\ A & 0 & 0 & 1 \\ B & 0 & 1 & 0 \\ C & 1 & 0 & 0 \end{bmatrix}$$

has an absorbing state in $B$; however, it is impossible to reach from either $A$ or $C.$ Note that an absorbing state can be reach indirectly through other states.

A MC is an absorbing chain if 1. There is at least one absorbing state; and 2. It is possible to go from each non-absorbing states to at least one absorbing state in a finite number of steps.

Absorbing MC are organized in standard form with absorbing states in the upper-left block submatrix as an identity matrix.

Consider the following transition diagram:



 <img src="https://user-images.githubusercontent.com/9312897/33806859-06ea036c-dd9c-11e7-8f67-eb85ff0d2b82.png">
 

The standard form will be:


$$\small\begin{align}
P=\begin{bmatrix}
& \text{A} & \text{non-A}\\
\text{A} & I & 0 \\
\text{non-A}& R & Q
\end{bmatrix}
=
\begin{bmatrix}
      & \text{B} & \text{A} & \text{C} & \text{D}\\
\text{B} &1       &  0       &   0      &   0      \\
\text{A} &.4     &  .6     &   0      &   0      \\
\text{C} &.7     &  0       &   0      &   .3    \\
\text{D} &0       &  0       &   1      &   0
\end{bmatrix}
\end{align}$$

Another example clarifies the block matrices. If we have a MC transition matrix given as

$$\small P=\begin{align}
\begin{bmatrix}
      & \text{A} & \text{B} & \text{C} & \text{D}\\
\text{A} &0       &  .3       &   .3      &   .4    \\
\text{B} &0       &  1         &   0        &   0      \\
\text{C} &0       &  0         &   1        &   0      \\
\text{D} &.8     &  .1       &   .1      &   0
\end{bmatrix}
\end{align}
$$

can be written in standard form as

$$\small\begin{align}
P=\begin{bmatrix}
      & \text{B} & \text{C} & \text{A} & \text{D}\\
\text{B} &1       &  0         &   0      &   0    \\
\text{C} &0       &  1         &   0        &   0      \\
\text{A} &.3       &  .3         &   0        &   .4      \\
\text{D} &.1     &  .1       &   .8      &   0
\end{bmatrix}
\end{align}
$$


The matrix $R=\begin{bmatrix}.3&.3\\.1&.1\end{bmatrix}$ and the matrix $Q= \begin{bmatrix}0&.4\\.8&0\end{bmatrix}.$

The limiting matrix, $\bar P$ is approached as powers of the standard form of the absorbing MC $P^k$ when $k$ increases as

$$\bar P =\begin{bmatrix}
I& 0\\ FR & 0
\end{bmatrix}$$

where the block matrix $FR$ is calculated from the fundamental matrix $F=(I-Q)^{-1}.$'

The $R$ matrix is not necessarily square: if there are $n_a$ absorbing states, and $n_t$ transient states, the matrix $R$ will be $n_t \times n_a,$ and contain the transition probabilities between transient and absorbent states. On the other hand, $Q$ is square, $n_t \times n_t,$ containing the transition probabilities between transient states. The submatrix $I$ will be square $n_a \times n_a,$ and the matrix of zeroes will be square and $n_t \times n_t.$

##### Properties:

1. The entry in row $i$, column $j$  of $\bar P$ is the long-run probability of going from state $i$ to state $j.$

2. The sum of the entries in each row of the fundamental matrix $F$ is the average number of trials it takes to go from each non-absorbing state to some absorbing state.

---

##### Proof:

[This](https://www.ssc.wisc.edu/~jmontgom/absorbingchains.pdf) is a good resource.
The submatrix $P$ contains the transition probabilities from transient to absorbing states, while $Q$ contains the transition probabilities from transient to transient states.

Powers of the transition matrix $P$ approach a limiting matrix with a pattern:

$$\begin{align}
P^2 &=\begin{bmatrix}I & 0 \\ R & Q \end{bmatrix}^2= \begin{bmatrix}I & 0 \\ R+QR & Q^2 \end{bmatrix}\\[3ex]
P^3 &=\begin{bmatrix}I & 0 \\ R+QR & Q^2 \end{bmatrix}\begin{bmatrix}I & 0 \\ R & Q \end{bmatrix}=\begin{bmatrix}I & 0 \\ R+QR+Q^2R & Q^3 \end{bmatrix}\\[3ex]
P^k &=\begin{bmatrix}I & 0 \\ \left(I+Q+Q^2+\cdots+Q^{k-1}\right)R & Q^k \end{bmatrix}\tag 1
\end{align}$$

The key now is that $Q^k\to 0$ as $k\to \infty.$

The fundamental matrix is a [geometric series](https://math.stackexchange.com/q/867768/152225):

$$F= I+Q+Q^2+\cdots=(I-Q)^{-1}$$

and replacing the expression $I+Q+Q^2+\cdots+Q^{k-1}$ in (1) with $F:$

$$\begin{align}P^{\infty}&=\begin{bmatrix}I & 0 \\ FR & 0 \end{bmatrix}\end{align}$$


---

##### Example problem:

Suppose a credit union classifies car loans into four categories: paid in full (F); in good standing (G); in arrears (A); or bad debt (B). Each month, $10\%$ of G accounts pay the loan in full; $80\%$ remain in G; and $10\%$ go to A. For accounts in A, $10\%$ are paid in full, $40\%$ become G; $40\%$ stay in A; and $10\%$ go to B:


 <img src="https://user-images.githubusercontent.com/9312897/33840499-1a6de0a8-de63-11e7-8c1c-585727467dae.png" width=300>

We want to know what percentage of accounts in A will default. And how many months the accounts in A will remain so, until they default or paid in full (the two absorbing states).

```{r}
(P = matrix(c(1,0,0,0,0,1,0,0,.1,0,.8,.1,.1,.1,.4,.4), nrow=4, byrow=T))
(R = P[3:4, 1:2])
(Q = P[3:4, 3:4])
(Fund = solve(diag(2) - Q)) 
(FR = Fund %*% R)
```

Just reading from the last matrix, $75\%$ of accounts in arrears (last row) will be paid in full (F), and $25\%$ will ultimately default. Likewise, of the good (G) accounts $87\%$ will ultimately be paid in full, and $13\%$ will default (B).


The average of months the accounts in A will remain in A before reaching an absorbing state (either F or B) will be

```{r}
rowSums(Fund)[2]
```

That is, an average of $7.5$ months until they are paid in full, or go into default.

The interpretation of the entries of the fundamental matrix, `Fund`, or $F$ in general is as follows: $F(i,j)$ is the number of periods (in this case, months) spent in the $j$ non-absorbing state when the chain started in the $i$ non-absorbing state. And $\sum_j F(i,j)$ yields the expected number of period spent in any non-absorbing state, given that we started at state $i,$ which is the calculation of $7.5$ months in the example above.

##### Proof:

Since

$$F = (I- Q)^{-1}= I + Q + Q^2 +\cdots$$

$$F(i,j) = Q^0(i,j) + Q^1(i,j) + Q^2(i,j)+\cdots$$

where $Q^t(i,j)$ is that the probability that the process that started in the $i$ non-absorbing state will be in the $j$ non-absorbing state at time $t.$ Or intepreted differently, the fraction of period $t$ spent in state $j.$ Therefore, the sum over all periods is the expected periods spent in $j.$


---


Finally, going back to the transition diagram above, all initial states will be unavoidably absorbed into B:

```{r}
(P = matrix(c(1,0,0,0,.4,.6,0,0,.7,0,0,.3,0,0,1,0), nrow=4, byrow=T))
R = P[2:4, 1, drop=F]
Q = P[2:4, 2:4]
Fund = solve(diag(3) - Q)
(FR = Fund %*% R)
```

We can see the absorbsion process in play if we focus back on the $P$ matrix of the insurance company example: 

```{r}
(P = matrix(c(1,0,0,0,0,1,0,0,.1,0,.8,.1,.1,.1,.4,.4), nrow=4, byrow=T))
```

After the second month...

```{r}
P%*%P
```

there'll be a lot of accounts in the transient states. But after six years there is no account in the transition states, having all been absorbed (notice the empty lower-right corner block matrix:

```{r, warning=F, message=F}
require(expm)
round(P %^% 75, 3)
```

---

#### Markov Chains and Ergodicity:

From [this post](https://twitter.com/normonics/status/1509234405222535180?s=20&t=rONOhathYVTHj9zam7aJTw) on Twitter by @normonics.

There were Markov chains without absorbing states that are non-ergodic, such as a simple random walk.

---

Conditions for **ergodicity**:

From [this presentation](https://youtu.be/YrTeOrRF0XA).

##### **Irreducibility**:

In a Markov transition matrix $P$ with $N$ states all the entries in $$\sum_{n=0}^{N-1} P^n$$

must be $>0.$

##### **Aperiodicity**:

The paths from one state to itself are not only multiples of a period $T \geq 2.$ It can be checked by finding a loop in the transition diagram of $k$ steps, and another loop of $k+1$ steps. Once is enough if irreducible. With transition matrices: Find $k$ and $i$ such that $P^k_{ii}P^{k+1}_{ii}>0.$

##### **Positive recurrence**: 

If I am at a given state the expected time before returning to that state is finite. If the matrix is irreducible and the number of states is finite, it is a given.

---

##### Example:

```{r}
library(expm)
# Example 1 -> 2 -> 3 -> 1
mat <- matrix(c(0,1,0,0,0,1,1,0,0),ncol=3,byrow=T)
mat
# Irreducible:
M <- matrix(rep(0,9),ncol=3)
for (i in 0:2) M <- M + mat %^% i
M
```



```{r}
# Aperiodic:
# Example: 1 -> 2 -> 3 -> 1
# If we want to move from 1 to itself we can do it in 3 steps or 6 or 9 or 12... So it's periodic with T = 3.
mat %^% 1
mat %^% 2
mat %^% 3

# P to the power of 3 is the identity. Same for any P to the power of 1 + 3k or 2 + 3k or 3 + 3k.
```

A state i is an absorbing state if once the system reaches state $i,$ it stays in that state; that is, $\Pr_{ii}=1$.

---

##### Non-ergodic chain with no absorbing state:

---

```{r}
trans_mat <- matrix(c(0,1/2,0,1/2,0,
                      0,1/2,1/2,0,0,
                      0,1/2,1/2,0,0,
                      0,0,0,1/2,1/2,
                      0,0,0,1/2,1/2),ncol=5,byrow=T)
N = 100
trans_mat %^% N
```

```{r}
# Check lack of irreducibility... number of states is 5:

M <- matrix(rep(0,25),ncol=5)
for (i in 0:4) M <- M + trans_mat %^% i
M
```

---

##### Non-ergodic chain with no absorbing state and each state with at least one incoming state:

---

```{r}
trans_mat <- matrix(c(0,1/2,0,1/2,0,
                      0,1/2,1/2,0,0,
                      0,1/2,1/2,0,0,
                      0,0,0,1/2,1/2,
                      1/10,0,0,4/10,1/2),ncol=5,byrow=T)
N = 100
trans_mat %^% N
```

---

##### Ergodic chain:

---

```{r}
trans_mat <- matrix(c(0,1/2,0,1/2,0,
                      0,1/2,1/2,0,0,
                      1/10,4/10,5/10,0,0,
                      0,0,0,1/2,1/2,
                      1/10,0,0,4/10,1/2),ncol=5,byrow=T)
N = 100
trans_mat %^% N
```


---
<a href="http://rinterested.github.io/statistics/index.html">Home Page</a>

**NOTE: These are tentative notes on different topics for personal use - expect mistakes and misunderstandings.**
